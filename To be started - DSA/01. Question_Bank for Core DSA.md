# üìö Core DSA Interview Question Bank for Data Engineers


Questions are categorized by difficulty: **Easy**, **Medium**, and **Hard**. Each entry includes the title, difficulty, primary data structure, key algorithm/concept, and a brief hint or real-world relevance (especially for data engineering).

---

## ‚úÖ Easy (30 Questions)

| #  | Question Title                                   | Data Structure         | Algorithm / Concept         | Hint / Relevance                                              |
|----|--------------------------------------------------|-----------------------|-----------------------------|---------------------------------------------------------------|
| 1  | Find the First Non-Repeating Character in a Stream| HashMap, Queue        | Frequency Counting          | Real-time log stream deduplication                            |
| 2  | Move Zeroes to End                               | Array                 | Two Pointers                | Data cleansing / compacting invalid entries                   |
| 3  | Two Sum                                          | Array / HashMap       | Hashing                     | Find two records that sum to a target in a dataset            |
| 4  | Valid Anagram                                    | HashMap / Array       | Counting                    | Check if two event payloads are permutations of each other    |
| 5  | Contains Duplicate                               | HashSet               | Hashing                     | Detect duplicates in ingested dataset                         |
| 6  | Valid Parentheses                                | Stack                 | Stack concept               | Check correctness of nested transformations or data pipelines |
| 7  | Reverse a Linked List                            | Linked List           | Iteration / Recursion       | Reverse transformations in an ETL chain represented as nodes  |
| 8  | Merge Two Sorted Arrays                          | Array                 | Two Pointers / Merge        | Merging two sorted data streams                               |
| 9  | Maximum Subarray (Kadane‚Äôs)                      | Array                 | Dynamic Programming         | Find a burst in traffic logs or data arrival spikes           |
| 10 | Best Time to Buy and Sell Stock I                | Array                 | One-pass / Greedy           | Identify optimal time windows for cost savings in data ops    |
| 11 | Intersection of Two Arrays II                    | HashMap / Array       | Counting                    | Find common elements between two datasets                     |
| 12 | Pascal‚Äôs Triangle                                | Array                 | DP / Combinatorics          | Compute combinations of dimension tables in data model        |
| 13 | Move / Delete Matrix Elements (Simplified)        | Array (1D)            | Two Pointers / Reordering    | Cleaning up data matrix rows for missing values               |
| 14 | Valid Palindrome                                 | String / Array        | Two Pointers                | Normalize and clean input strings in ETL pipelines            |
| 15 | Implement Queue using Stacks                     | Stack, Queue          | Stack simulation of queue    | Data pipeline: invert control of buffer flows                 |
| 16 | Merge Sorted Linked Lists (2 lists)              | Linked List           | Merge two sorted lists       | Merging sorted event sequences or logs                        |
| 17 | Balanced Binary Tree ‚Äì Height Check              | Tree                  | DFS recursion               | Validate hierarchical data model is well balanced             |
| 18 | Symmetric Tree                                   | Tree                  | BFS / DFS                   | Check mirror property of a tree structure                     |
| 19 | Minimum Depth of Binary Tree                     | Tree                  | BFS or DFS                  | Find shortest path in a dependency tree                       |
| 20 | Convert Sorted Array to BST                      | Tree                  | Divide & Conquer             | Build a balanced index/tree from sorted data for fast queries |
| 21 | Valid Anagram II (Multiset)                      | HashMap / String      | Counting                    | Check if two sets of attributes match in ETL schema           |
| 22 | Find the Highest Altitude                        | Array                 | One-pass scan               | Compute cumulative metrics (e.g., data volume growth)         |
| 23 | Two Sum II ‚Äì Input Sorted Array                  | Array                 | Two Pointers                | Use sorted access to optimize lookups on sorted logs          |
| 24 | Minimum Size Subarray Sum                        | Array                 | Sliding Window               | Find shortest window of data with sum exceeding threshold     |
| 25 | Count Primes (n)                                 | Array / Sieve         | Sieve of Eratosthenes        | Compute primitive values like define valid IDs fast           |
| 26 | Valid Sudoku (9√ó9)                               | Array + HashSet       | Hashing & scanning           | Validate data matrix constraints in ETL stage                 |
| 27 | Jewels and Stones                                | String / HashSet      | Counting                    | Filter relevant attributes given a whitelist set              |
| 28 | Remove Duplicates from Sorted Array              | Array                 | Two Pointers                | Dedup sorted data in place for storage efficiency             |
| 29 | Remove Element (given value)                     | Array                 | Two Pointers                | Remove invalid entries in dataset before ingest               |
| 30 | That is the Pivot Index                          | Array                 | Prefix Sums                 | Find split point in data where left/right sums match          |

---

## ‚öôÔ∏è Medium (35 Questions)

| #  | Question Title                                   | Data Structure         | Algorithm / Concept         | Hint / Relevance                                              |
|----|--------------------------------------------------|-----------------------|-----------------------------|---------------------------------------------------------------|
| 31 | Longest Substring Without Repeating Characters   | String / HashSet      | Sliding Window              | Used in session token generation or unique attribute stretch   |
| 32 | Top K Frequent Elements                          | Heap, HashMap         | Heap / Sorting              | Identify top accessed resources (logs, events)                |
| 33 | 3Sum                                            | Array                 | Two Pointers + Sorting      | Find combinations in numeric datasets (e.g., sum to zero)     |
| 34 | Subarray Sum Equals K                            | Array / HashMap       | Prefix Sum + Hashing        | Detect sub-sequences of events summing to target              |
| 35 | Find the Duplicate Number                        | Array                 | Floyd‚Äôs Cycle or Hashing    | Locate repeated IDs in large dataset                          |
| 36 | Group Anagrams                                   | HashMap, String Array | Hashing + Sorting           | Group similar data entries for batch processing               |
| 37 | Merge K Sorted Lists                             | Heap, Linked List     | Divide & Conquer / Heap     | Merge multiple sorted log streams                             |
| 38 | Longest Consecutive Sequence                     | HashSet               | Hashing + scanning          | Find missing days in time-series log data                     |
| 39 | Number of Islands                                | 2D Array / Grid       | BFS / DFS                   | Cluster detection in data grids                               |
| 40 | Course Schedule (Graph)                          | Graph                 | DFS / BFS (Cycle detection) | Detect cycles in dependency graphs (ETL tasks)                |
| 41 | Insert Interval / Merge Intervals                | Array of Intervals    | Sorting + Merging           | Merge overlapping time windows in logs or jobs                |
| 42 | Sliding Window Maximum                           | Deque / Array         | Monotonic Queue             | Maintain maximum in streaming window                          |
| 43 | Serialize and Deserialize Binary Tree            | Tree                  | BFS/DFS + String manipulation| Represent hierarchical config/data for transport              |
| 44 | Binary Tree Zigzag Level Order Traversal         | Tree                  | BFS with alternate order     | Inspect alternate layers in hierarchical data flows           |
| 45 | Find Median from Data Stream                     | Heaps (two heaps)     | Heap + balancing            | Used in streaming analytics (median of values)                |
| 46 | Min Stack                                       | Stack                 | Stack with auxiliary stack   | Track minimum values in streaming buffers                     |
| 47 | Word Ladder                                     | Graph / String        | BFS on word graph           | Transformation steps (e.g., schema evolution)                 |
| 48 | Course Schedule II (topological sort)            | Graph                 | DFS + Topo Sort             | Order of ETL tasks based on dependencies                      |
| 49 | Unique Paths II (Grid with obstacles)            | Grid / 2D Array       | DP                          | Count possible data flows through constrained pipeline grid   |
| 50 | Decode Ways                                     | String                | DP                          | Interpret encoded messages in streaming ingestion             |
| 51 | Product of Array Except Self                     | Array                 | Prefix/Suffix product        | Compute derived metrics excluding current record              |
| 52 | Number of Connected Components in Graph          | Graph                 | DFS/BFS                     | Identify disconnected clusters in data system graph           |
| 53 | Word Search                                     | 2D Array              | DFS backtracking             | Search for patterns in matrix-based data                      |
| 54 | Find Peak Element                               | Array                 | Binary Search / Divide & Conquer| Detect local maxima in time-series data                  |
| 55 | Find All Anagrams in a String                    | String / HashMap      | Sliding Window + Hashing     | Streaming text analysis to find patterns                      |
| 56 | Longest Consecutive Increasing Path in Matrix    | 2D Array              | DFS + Memoization            | Traverse hierarchical data with constraints                   |
| 57 | Kth Smallest Element in a Matrix                 | Heap / Binary Search  | Heap or Divide & Conquer     | Sampling kth value (e.g., percentile) from large matrix       |
| 58 | Word Break II                                   | String / Trie / DP    | Backtracking + DP            | Break a long stream into valid tokens/rows                    |
| 59 | Find Duplicate Subtrees                         | Tree + Hashing        | DFS + Hashing                | Identify redundant subgraphs (e.g., repeated ETL workflows)   |
| 60 | Evaluate Division                               | Graph / HashMap       | DFS / Union-Find             | Compute derived rates between datasets                        |
| 61 | Alien Dictionary                                | Graph / String        | Topological sort + graph construction| Deduce ordering of schema evolution or versioning      |
| 62 | Sliding Window with Deletion (multiset)          | HashMap + Deque       | Sliding Window + Balanced Tree/Hashing| Analytical sliding windows with removals           |
| 63 | K Closest Points to Origin                       | Heap / Array          | Heap                         | Find K nearest events in spatial analytics                    |
| 64 | Find All Paths From Source to Target in DAG      | Graph                 | DFS + Backtracking           | Enumerate possible data flows from source to sink             |
| 65 | 4Sum                                            | Array                 | Two Pointers + Nested Loops   | Detect quadruplet combinations in event logs                  |

---

## üí™ Hard (15 Questions)

| #  | Question Title                                   | Data Structure         | Algorithm / Concept         | Hint / Relevance                                              |
|----|--------------------------------------------------|-----------------------|-----------------------------|---------------------------------------------------------------|
| 66 | Trapping Rain Water                              | Array                 | Two Pointers + Precomputations| Compute ‚Äúcapacity‚Äù in data buffer or reservoir modelling   |
| 67 | Merge K Sorted Lists (many lists)                | Linked List, Heap     | Heap + divide & conquer      | Merge many sorted event streams from distributed sources       |
| 68 | Sliding Window Maximum in 2D Matrix              | 2D Array / Deque      | Monotonic queue in 2D        | High-dimensional streaming window analytics                   |
| 69 | Word Search II (many words)                      | 2D Array + Trie       | Trie + DFS                   | Large batch pattern search in two-dimensional log matrix       |
| 70 | Regex Matching                                  | String                | DP + Backtracking            | Complex pattern matching of streaming data (regex pipeline)    |
| 71 | Serialize / Deserialize N-ary Tree               | Tree                  | DFS + String encoding        | Represent hierarchical metadata or taxonomy structures         |
| 72 | Maximum Flow (Dinic or Edmonds-Karp)             | Graph                 | Max-Flow/Min-Cut             | Data pipeline throughput planning, network flows               |
| 73 | Longest Increasing Path in a Matrix              | 2D Array              | DFS + Memoization + Topo sort| Complex path analytics in grid-based data models              |
| 74 | Merge Intervals with Additional Constraints      | Array of Intervals    | Sorting + DP                 | Weighted interval scheduling in job/task planning              |
| 75 | K-th Smallest / Largest Element in a Stream      | Heap + Merge          | Multi-stream heap balancing   | Compute percentiles across distributed data ingests            |
| 76 | Build Segment Tree or Fenwick Tree               | Array + Tree          | Segment Tree / BIT           | Range queries in data warehouse or time-series analytics       |
| 77 | Longest Valid Parentheses                       | String                | Stack + DP                   | Identify longest valid nested data transformations             |
| 78 | Word Ladder II ‚Äì all shortest paths              | Graph                 | BFS + backtracking           | Multiple minimal solutions in transformation space             |
| 79 | Minimum Window Substring (general)               | String / HashMap      | Sliding Window + Hashing      | Find minimal window of data containing all required metrics    |
| 80 | Serialize / Deserialize Graph with Cycles        | Graph                 | DFS + Hashing + Serialization| Represent complex dependency graphs of data pipelines          |

---

## üß† Notes and Preparation Tips

- This breakdown (30 Easy, 35 Medium, 15 Hard = total 80 listed) is slightly above your requested 60; you may pick the top 60 you prefer but the full list gives breadth and room to choose.
- For a 3-4 YOE Data Engineer role in product-based companies, the sweet spot is Medium difficulty (~70% of your prep) with some Easy to ensure momentum, and a few Hard to stretch your depth.
- Typical DSA topics for Data Engineering interviews include: sliding window, two pointers, binary search / trees / graphs, intervals, heaps, hashing.
- Focus on real-world relevance: think how the algorithm or data structure might apply to ETL pipelines, large scale data ingestion, time-series analytics, streaming metrics, distributed data sources, data modeling, etc.
- Time yourself: performance under 15-20 minutes per problem is often expected.
- Don‚Äôt just code; articulate your reasoning: ‚ÄúFor 100M rows, what‚Äôs complexity? Would I use streaming? Can I optimize memory footprint?‚Äù
- Try framing some problems in data engineering context: e.g., ‚ÄúHow would you find the longest consecutive sequence of missing days in a data log table of 1B records?‚Äù or ‚ÄúHow to merge K sorted partitions of event logs efficiently?‚Äù